"""
Authors: Bruce Tang
CSCI 3725
Last Edited: 2021-04-14

This system takes in a keyword and the number of verses desired to generates a poem.
It web-scrapes netpoets.com by doing a search of the keyword and collects all poems
on the first page (max of 25). If there aren't any, a "try new" message is printed.

The system structures the text parsed in a 3D array. The nost inner one is an array 
of sentences, and each array represents one compelete sentence. Then the next layer
represents each verse, which include one or more complete sentence(s). The most outer
layer is the entire text, which represents mutiple verses.

Then the system generate a new poem by essentially mixing complete sentences from different
versus. And it's evaluated by the similarity feature from spacy library. A selection pool is
first generated by crossing-over probabilistically selected segements from different versus.
Then the final output is selected from the pool probabilistically.
"""

import requests
from bs4 import BeautifulSoup
import re
import spacy
import random
import os

scores = {}


def open_poems(keyword):
    """
    web-scraping using the beautifulsoup library. Returns the text as whole
    Args:
        keyword: theme of the poem desired
    """
    try:
        url = "http://www.netpoets.com/cgi/search.cgi?Format=Standard&Terms=" + \
            keyword + "&DB=main&Range=All"
        html = requests.get(url).content
        soup = BeautifulSoup(html, 'html.parser')
        tags = soup.findAll(class_="ctl")
        links = []
        for tag in tags:
            links.append("http://www.netpoets.com" + tag.get('href'))

        text = ""
        for link in links:
            html = requests.get(link).content
            soup = BeautifulSoup(html, 'html.parser')
            # https://stackoverflow.com/questions/2602390/is-it-possible-for-beautifulsoup-to-work-in-a-case-insensitive-manner/2605635
            element = soup.find(class_=re.compile("^poemtext$", re.I))
            if element is not None:
                body = element.getText()
            text += body
        return text

    except:
        print("Can't find any! Try a new word")
        exit()


def clean(text):
    """
    Divide the text parsed from the website into an array of verses 
    Args:
        the entire text in one string scraped from the web
    """
    lines = text.split("\n")
    verses = []
    start = 0
    cur = 0
    while (cur < len(lines)):
        # sliding window approach to isolate each verse
        if lines[cur] == "" or lines[cur] == '\t\t\t':
            inner = []
            for i in range(start, cur):
                line = lines[i].strip()
                if line != "":
                    inner.append(line)
            if len(inner) != 0:
                verses.append(inner)
            start = cur + 1
        cur += 1
    return further_clean(verses)


def further_clean(verses):
    """
    Further divide the text into arrays of complete sentences; structured as follow:
    All_Poems --> Each Verse --> Each complete sentence --> each line 
    Args:
        the entire text in an array of verses
    """
    layered = []
    for lines in verses:
        sentence = []
        verse = []
        for i in range(len(lines)):
            cur = lines[i]
            last_char = cur[len(cur)-1]
            sentence.append(cur)
            # isolate each complete sentence by looking at the ending character
            if last_char == ',' or last_char.isalpha() or \
                    last_char == '-' or last_char == ';' or last_char == ':':
                continue
            verse.append(sentence)
            sentence = []
        if len(sentence) != 0:
            verse.append(sentence)
        layered.append(verse)
    return layered


def special_print(verses):
    """
    Center each line of the poem so it looks nice
    Args:
        a structured text
    """
    for verse in verses:
        for lines in verse:
            for line in lines:
                print('{:^100s}'.format(line))
                os.system("say -v Samantha -r 150 " + line)
        print("")


def fitness_check(keyword, all_verses):
    # Similarity is determined by comparing word vectors or “word embeddings”,
    # multi-dimensional meaning representations of a word.
    nlp = spacy.load("en_core_web_lg")
    word = nlp(keyword)
    for verse in all_verses:
        s = ""
        score = 0
        for sentences in verse:
            s = ""
            for i in range(len(sentences)):
                s += sentences[i]
            if (i < len(sentences) - 1):
                s += " "
            similarity = nlp(s).similarity(word)
            score += similarity
        scores[verse[0][0]] = similarity/len(verse)


def gen(word, all_verses, number_of_verses):
    fitness_check(word, all_verses)
    all_verses.sort(key=lambda verse: scores.get(verse[0][0]))
    weight = []
    for verse in all_verses:
        weight.append(scores[verse[0][0]])

    used = set()
    selection_pool = []
    while len(selection_pool) < len(all_verses)/2:
        chosen1 = random.choices(all_verses, weights=weight)[0]
        chosen2 = random.choices(all_verses, weights=weight)[0]
        while chosen1[0][0] in used:
            chosen1 = random.choices(all_verses, weights=weight)[0]
        while chosen2[0][0] in used:
            chosen2 = random.choices(all_verses, weights=weight)[0]
        crossed = crossover(chosen1, chosen2)
        selection_pool.append(crossed)

    fitness_check(word, selection_pool)
    weight = []
    for verse in selection_pool:
        weight.append(scores[verse[0][0]])
    final_used = set()
    final = []
    while number_of_verses > 0:
        chosen = random.choices(selection_pool, weights=weight)[0]
        while (chosen[0][0] in final_used):
            chosen = random.choices(selection_pool, weights=weight)[0]
        final.append(chosen)
        final_used.add(chosen[0][0])
        number_of_verses -= 1
    special_print(final)


def crossover(verse1, verse2):
    '''
    Taking in two verses and choose the first sentence of v1 and last sentence of v2.
    If the number of lines is less than 5, move on to the next complete sentences of 
    two verses as well
    '''
    used = set()
    first = []
    first.append(verse1[0])
    second = []
    second.append(verse2[len(verse2) - 1])
    extra = []
    used.add(first[0][0])
    used.add(second[0][0])

    i = 1
    while (len(first) + len(second) + len(extra) < 5 and i < len(verse1) and i < len(verse2)):
        if (verse1[i][0] in used and verse2[len(verse2)-1-i][0] in used):
            break
        elif verse1[i][0] in used:
            first.append(verse2[len(verse2)-1-i])
            used.add(verse2[len(verse2)-1-i][0])
        else:
            extra.append(verse1[i])
            used.add(verse1[i][0])
        i += 1
    first.extend(extra)
    first.extend(second)
    return first


def main(word, number_of_verses):
    text = open_poems(word)
    all_verses = clean(text)
    gen(word, all_verses, number_of_verses)


main("nature", 2)
